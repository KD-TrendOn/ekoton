Ты оператор проекта по созданию платформы для департамента экологии "Красная книга". 
project_root/
├── app/
│   ├── api/
│   │   ├── v1/
│   │   │   ├── endpoints/
│   │   │   │   ├── submissions.py
│   │   │   │   ├── admin.py
│   │   │   │   ├── tasks.py
│   │   │   │   └── reports.py
│   │   │   ├── __init__.py
│   │   ├── dependencies.py
│   │   └── __init__.py
│   ├── core/
│   │   ├── config.py
│   │   ├── logger.py
│   │   └── __init__.py
│   ├── ml/
│   │   ├── classifier.py
│   │   ├── train.py
│   │   └── requirements.txt
│   ├── schemas/
│   │   ├── submissions.py
│   │   ├── admin.py
│   │   ├── tasks.py
│   │   ├── reports.py
│   │   └── __init__.py
│   ├── main.py
│   └── __init__.py
├── db/
│   ├── models/
│   │   ├── base.py
│   │   ├── user.py
│   │   ├── moderator.py
│   │   ├── submission.py
│   │   ├── task.py
│   │   ├── report.py
│   │   ├── flora_fauna.py
│   │   ├── area.py
│   │   └── __init__.py
│   ├── crud.py
│   ├── db_helper.py
│   └── __init__.py
├── tests/
│   ├── test_submissions.py
│   ├── test_admin.py
│   ├── test_tasks.py
│   ├── test_reports.py
│   └── __init__.py
├── requirements.txt
├── README.md
└── .env

app/api/v1/endpoints/submission.py

from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Form
from typing import Any
import base64
from app.schemas.submissions import SubmissionCreate, SubmissionResponse
from app.ml.classifier import classify_image
from db.crud import create_submission
from db.models import Submission
from db.db_helper import db_helper
from sqlalchemy.ext.asyncio import AsyncSession
from app.api.dependencies import get_current_user

router = APIRouter(
    prefix="/submissions",
    tags=["Submissions"],
)

@router.post("/", response_model=SubmissionResponse)
async def create_user_submission(
    image: UploadFile = File(...),
    latitude: float = Form(...),
    longitude: float = Form(...),
    current_user: Any = Depends(get_current_user),
    session: AsyncSession = Depends(db_helper.get_session),
):
    # Проверка типа файла
    if image.content_type not in ["image/jpeg", "image/png"]:
        raise HTTPException(status_code=400, detail="Invalid image type.")

    # Чтение изображения
    content = await image.read()
    encoded_image = base64.b64encode(content).decode('utf-8')

    # Классификация изображения
    object_class = classify_image(content)

    # Создание объекта Submission
    submission = Submission(
        user_id=current_user.id,
        image=encoded_image,
        latitude=latitude,
        longitude=longitude,
        object_class=object_class,
    )

    # Сохранение в базу данных
    await create_submission(session, submission)

    return SubmissionResponse(
        id=submission.id,
        object_class=submission.object_class,
        latitude=submission.latitude,
        longitude=submission.longitude,
        status=submission.status,
        created_at=submission.created_at,
    )

app/core/config.py
from pydantic import BaseSettings

class Settings(BaseSettings):
    DATABASE_URL: str
    DB_ECHO: bool = False
    POSTGRES_HOST: str
    POSTGRES_PORT: int
    POSTGRES_USER: str
    POSTGRES_PASSWORD: str
    POSTGRES_DB: str
    # Добавь другие настройки при необходимости

    class Config:
        env_file = ".env"

settings = Settings()

app/core/logger.py

import logging

def setup_logger(name: str) -> logging.Logger:
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)

    handler = logging.StreamHandler()
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)

    return logger

logger = setup_logger(__name__)

app/schemas/submissions.py

from pydantic import BaseModel
from datetime import datetime

class SubmissionCreate(BaseModel):
    latitude: float
    longitude: float

class SubmissionResponse(BaseModel):
    id: int
    object_class: str
    latitude: float
    longitude: float
    created_at: datetime

    class Config:
        orm_mode = True

db/models/base.py
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column, declared_attr

class Base(DeclarativeBase):
    __abstract__ = True

    @declared_attr.directive
    def __tablename__(cls) -> str:
        return f"{cls.__name__.lower()}s"

    id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True)

db/models/flora_fauna.py

from sqlalchemy import Column, String, Text, Integer
from .base import Base

class FloraFauna(Base):
    __tablename__ = "flora_fauna"

    name = Column(String, unique=True, index=True, nullable=False)
    description = Column(Text, nullable=True)
    category = Column(String, nullable=False)  # 'flora' или 'fauna'
    habitat = Column(String, nullable=True)
    characteristics = Column(Text, nullable=True)

db/models/moderator.py
from sqlalchemy import Column, String, DateTime, Integer
from sqlalchemy.sql import func
from .base import Base

class Moderator(Base):
    __tablename__ = "moderators"

    username = Column(String, unique=True, index=True, nullable=False)
    email = Column(String, unique=True, index=True, nullable=False)
    password_hash = Column(String, nullable=False)
    created_at = Column(DateTime(timezone=True), server_default=func.now())

db/models/report.py

from sqlalchemy import Column, String, Text, DateTime, Integer
from sqlalchemy.sql import func
from .base import Base

class Report(Base):
    __tablename__ = "reports"

    generated_at = Column(DateTime(timezone=True), server_default=func.now())
    content = Column(Text, nullable=False)  # JSON или текст отчета

db/models/submission.py

from sqlalchemy import Column, Integer, String, Float, DateTime
from sqlalchemy import Column, String, Float, DateTime, ForeignKey
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func
from .base import Base

class Submission(Base):
    __tablename__ = "submissions"

    image = Column(String, nullable=False)  # base64 строка изображения
    latitude = Column(Float, nullable=False)
    longitude = Column(Float, nullable=False)
    object_class = Column(String, nullable=False)  # 'flora' или 'fauna'
    status = Column(String, default="pending")  # 'pending', 'approved', 'rejected'
    created_at = Column(DateTime(timezone=True), server_default=func.now())

db/models/task.py

from sqlalchemy import Column, String, Text, DateTime, Boolean, Integer, ForeignKey
from sqlalchemy.sql import func
from .base import Base
from sqlalchemy.orm import relationship
class Task(Base):
    __tablename__ = "tasks"
    image = Column(Text, nullable=False)
    title = Column(String, nullable=False)
    description = Column(Text, nullable=True)
    target_flora = Column(String, nullable=True)  # Названия растений
    target_fauna = Column(String, nullable=True)  # Названия животных
    is_active = Column(Boolean, default=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now())

db/crud.py

# db/crud.py

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from sqlalchemy.orm import selectinload
from db.models import Submission, User
from typing import List

async def create_submission(session: AsyncSession, submission: Submission) -> Submission:
    session.add(submission)
    await session.commit()
    await session.refresh(submission)
    return submission

async def get_submissions(session: AsyncSession, skip: int = 0, limit: int = 10) -> List[Submission]:
    stmt = select(Submission).offset(skip).limit(limit)
    result = await session.execute(stmt)
    return result.scalars().all()

async def get_submission_by_id(session: AsyncSession, submission_id: int) -> Submission:
    stmt = select(Submission).where(Submission.id == submission_id).options(selectinload(Submission.user))
    result = await session.execute(stmt)
    return result.scalar_one_or_none()

# Добавь аналогичные функции для других моделей по необходимости

db/db_helper.py

from sqlalchemy.ext.asyncio import (
    AsyncSession,
    create_async_engine,
    async_sessionmaker,
    async_scoped_session,
)
from app.core.config import settings
from asyncio import current_task

class DatabaseHelper:
    def __init__(self, url: str, echo: bool = False):
        self.engine = create_async_engine(url=url, echo=echo)
        self.session_factory = async_sessionmaker(
            bind=self.engine,
            autoflush=False,
            autocommit=False,
            expire_on_commit=False,
        )

    async def get_session(self) -> AsyncSession:
        async with self.session_factory() as session:
            yield session
    
    def get_scoped_session(self):
        session = async_scoped_session(
            session_factory=self.session_factory,
            scopefunc=current_task,
        )
        return session

    async def session_dependency(self) -> AsyncSession:
        async with self.session_factory() as session:
            yield session
            await session.close()

    async def scoped_session_dependency(self) -> AsyncSession:
        session = self.get_scoped_session()
        yield session
        await session.close()

db_helper = DatabaseHelper(url=settings.DATABASE_URL, echo=settings.DB_ECHO)



Платформа для граждан и краудсорсинг заказов.

Идея - департамент направляет задание на сайт которое отображается у всех пользователей. 






Нужно создать веб ресурс где пользователи смогут отправить фотографию и указать данные о местоположении сделанной фотографии. Они делают это следующим способом.





Разрешить получить данные о текущей геолокации. 
Затем отправляется json на сервер, который содержит в себе base64 долготу и широту
затем классификатор определяет что это за объект (животное или растение).
После того, как классификатор смог распознать объект в бд отправляется данные (Время добавления, название объекта, долгота и широта).

Админ панель должна включать в себя удобный просмотр карты, получение данных о конкретных данных флоры и фауны обитающих в конкретном месте, слой модерации которые фильтруют данные перед тем как они попадут в другие функции админ панели, получение данных о конкретном объекте (растение или животное), создание и отправку заданий)

Сделать платформу для модераторов.
Во первых соответствует имя объекта на объект на фотографии
Можно как привлекать граждан


Надо учитывать какая должна быть экология рядом с животным или растением. 




Привлечение пользователей системой вознаграждений. 



Комментарий эксперта.
Понятно места где будем отмечать места растения или животным и желательно чтобы были характеристики по видам. 

Больше по механики, нейронку можно потом обозначить. Вы не успеете сделать за 2 дня. Надо сделать mvp. 

Важно учитывать что задача так же включает в себя строительство. 

Я ЗАНИМАЮСЬ БЭКЕНДОМ. Моя задача сделать на fastapi доступ к нейронке которая классифицирует изображение, для прототипа можно взять самую простую с самым простым датасетом.

У меня должно быть хранилище json в которых лежат изображения, класс животного и метка геолокации которые потом фронтенд полностью одним запросом получает.

У меня должна быть база данных postgres, в ней должны быть:
Таблица с модераторами, таблица с выполненными задачами модераторов(они перепроверяют изображение после нейронки)

База данных с информацией о животных живущих в парке москвы. Мы можем постараться сами ее собрать из википедии.

Там должно быть много характеристик.

Также мы должны собрать информацию о мини областях в Москве, кадастрах и кадастровых номерах. Апи должно предоставлять отчет по полученным изображениям в пределах этой области.

Задания департамента - от них это просто запрос на платформу о том, что в некоторой области они собираются запросить у граждан фотографии флоры и фауны, а гражданам пользователям на платформе можно зайти на это задание и сфоткать что то и получить бонусы.(систему с бонусами делать для mvp не надо)


Теперь про api и нейронку.
Давай сделаем прогу для ее обучения, и потом в api посмотрим как будет выглядеть inference.

Далее нужно сделать все описанные функциональные компоненты, эндпоинты к ним, а также задуматься как департамент может их изменять и расширять. Оцениваться будет именно кодовая база, поэтому хорошо поработаем над проектом.

Нам не нужно сейчас думать про геолокацию заданий и отчетов, а также я удалил файл users. Мы не будем делать регистрацию, и геолокация для mvp будет только одна - заповедник Москворечье. Его рамки по широте и долготе у меня есть, будем его считать за прямоугольник.

Давай продолжать работу по тем файлам которые есть и которых нет. Нам во первых нужно поменять роутер для загрузки фото, так как фронтенд будет отправлять мне image:base64, latitude:float и longitude:float. И не надо это делать через forms, лучше через post запрос и получение определенного json.

Насчет нейронной сети:
Мы будем использовать дообученный на классификацию животных openclip:

Haofeng
/
CLIP_animal_classification 

like
0

License:
mit
Model card
Files and versions
Community
Overview
This model is based on CLIP model and test on four kinds of animal datasets and ten kinds of animal datasets. CLIP model is a zero-shot pre-trained model so we don't need train model. We just input possible classes and image dataset to use model. Possible classes can be defined by yourself, it can be dataset labels or other description.

Text-image matching
Model Input
Class = ["dog", "cat", "rabbit","squirrel"]
image = preprocess(Image.open("/content/drive/MyDrive/Transformer_CLIP/Golden_Retriever.jpeg")).unsqueeze(0).to(device)
text = clip.tokenize(Class).to(device)

Model Process
with torch.no_grad():
    image_features = model.encode_image(image)
    text_features = model.encode_text(text)
    
    logits_per_image, logits_per_text = model(image, text)
    probs = logits_per_image.softmax(dim=-1).cpu().numpy()

res = 0
pos = -1
for j in range(len(probs[0])):
  if probs[0][j] > res:
    res = probs[0][j]
    pos = j


print("The options available are: " + str(Class))
for i in range(len(probs[0])):
  print("The probability of " + str(Class[i]) + " is " + str(probs[0][i]))

print("Model thinks this photo is most likely a " + Class[pos])


# Другой файл

!pip install ftfy regex tqdm
!pip install git+https://github.com/openai/CLIP.git
Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (6.1.1)
Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)
Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)
Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)
Collecting git+https://github.com/openai/CLIP.git
  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-06_4ghuz
  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-06_4ghuz
Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (6.1.1)
Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)
Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.64.0)
Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.10.0+cu111)
Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.11.1+cu111)
Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (4.1.1)
Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)
Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.21.6)
import os
import numpy as np
import torch
import clip
import cv2
from PIL import Image
from google.colab import drive
drive.mount('/content/drive')
Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
Class = ["Buffalo", "Elephant", "Rhino","Zebra"]
Class_dic = {1:"Buffalo", 2:"Elephant", 3:"Rhino", 4:"Zebra"}
image_labels = []
image_file = []
path = "/content/drive/MyDrive/Transformer_CLIP/Data"


for i in Class:
    paths = path + '/' + i
    images = os.listdir(paths)

    for img in images:
        
        try:
            image_file.append(paths + '/' + img)
            image_labels.append(i)
        except:
            print("Error in " + img)

print(len(image_file))
4003
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)
predict = []
for i in image_file:
  image = preprocess(Image.open(i)).unsqueeze(0).to(device)
  text = clip.tokenize(["Buffalo", "Elephant", "Rhino","Zebra"]).to(device)

  with torch.no_grad():
      image_features = model.encode_image(image)
      text_features = model.encode_text(text)
      
      logits_per_image, logits_per_text = model(image, text)
      probs = logits_per_image.softmax(dim=-1).cpu().numpy()
  
  res = 0
  pos = -1
  for j in range(len(probs[0])):
    if probs[0][j] > res:
      res = probs[0][j]
      pos = j + 1
  predict.append(Class_dic[pos])
print(predict)

Начнем работу.